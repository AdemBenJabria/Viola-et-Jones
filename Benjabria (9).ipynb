{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9d43faa-966e-4c68-a5b9-c6391e37e681",
   "metadata": {},
   "source": [
    "### Adem BEN JABRIA\n",
    "#### Université Côte d'Azur - M2 MIAGE IA2\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06dc1671-0d07-4d8b-a090-17aa9dd64b8d",
   "metadata": {},
   "source": [
    "### Explication des Fichiers Pickle et du Jeu de Données\n",
    "\n",
    "#### Fichiers Pickle :\n",
    "\n",
    "1. **training.pkl** : \n",
    "   - Contient des données d'entraînement.\n",
    "   - Format : Array de tuples (Image en numpy array, Classification (1 pour visage, 0 pour non-visage)).\n",
    "   - Comprend 2 429 images de visages et 4 548 images sans visages.\n",
    "\n",
    "2. **test.pkl** :\n",
    "   - Contient des données de test.\n",
    "   - Format similaire à `training.pkl`.\n",
    "   - Comprend 472 images de visages et 23 573 images sans visages.\n",
    "\n",
    "3. **Modèles Pickle (50.pkl, 200.pkl, cascade.pkl)** :\n",
    "   - **50.pkl** : Classifieur Viola-Jones entraîné avec 50 caractéristiques.\n",
    "   - **200.pkl** : Classifieur Viola-Jones entraîné avec 200 caractéristiques.\n",
    "   - **cascade.pkl** : Cascade de classifieurs Viola-Jones examinant respectivement 1, 5, 10 et 50 caractéristiques.\n",
    "\n",
    "#### Jeu de Données :\n",
    "- Les données proviennent de la CBCL Face Database du MIT. téléchargeable ici : http://cbcl.mit.edu/software-datasets/FaceData2.html\n",
    "- Chaque image est en niveaux de gris et de dimension 19x19 pixels.\n",
    "\n",
    "### Avantage de cette Version de Viola-Jones :\n",
    "- La présence de classifieurs déjà entraînés permet d'économiser du temps en évitant le processus d'entraînement long et complexe.\n",
    "---\n",
    "\n",
    "#### Charger et Tester un Classifieur Entraîné :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73112c0f-2065-45a9-84da-1bd88ce767c6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on a small test set: 0.3\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from viola_jones import ViolaJones\n",
    "\n",
    "# Charger le modèle\n",
    "model_file = \"200.pkl\" \n",
    "with open(model_file, 'rb') as f:\n",
    "    clf = pickle.load(f)\n",
    "\n",
    "# Charger les données de test\n",
    "with open(\"test.pkl\", 'rb') as f:\n",
    "    test_data = pickle.load(f)\n",
    "\n",
    "# Tester le modèle sur quelques images\n",
    "correct, total = 0, 0\n",
    "for image, label in test_data[:20]:  # Tester sur les 20 premières images\n",
    "    prediction = clf.classify(image)\n",
    "    correct += 1 if prediction == label else 0\n",
    "    total += 1\n",
    "\n",
    "print(f\"Accuracy on a small test set: {correct / total}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e981157-e4a3-4c87-a6aa-b93e9fdae794",
   "metadata": {},
   "source": [
    "# Exercice 1 \n",
    "**Remplacer les méthodes CPU intensives en Python classique par des versions GPU/CUDA**\n",
    "- Scan inclusif\n",
    "- Transposé de matrice\n",
    "- Calcul de l'image intégrale\n",
    "- Tout autre méthode qui pourrait bénéficier du GPU  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055f44a9-5252-4bf6-b325-888aa559a909",
   "metadata": {},
   "source": [
    "## Changements Apportés au Code pour Optimisation GPU/CUDA\n",
    "\n",
    "### Remplacements Globaux\n",
    "\n",
    "- **Importation de CuPy :** Remplacement de `numpy` par `cupy` pour exploiter les capacités du GPU.\n",
    "\n",
    "### viola_jones.py\n",
    "1. **Remplacement de NumPy par CuPy**: \n",
    "   - Utilisation de CuPy pour une exécution plus rapide sur les GPU.\n",
    "   - Cela concerne toutes les opérations matricielles et les calculs d'images intégrales.\n",
    "\n",
    "2. **Modification de la méthode `integral_image`**:\n",
    "   - La fonction `integral_image` a été modifiée pour utiliser CuPy, accélérant ainsi le calcul des images intégrales.\n",
    "\n",
    "3. **Ajout des fonctions `scan_inclusive` et `transpose_matrix`**:\n",
    "   - Ces fonctions utilisent CuPy pour réaliser un scan inclusif et une transposition de matrice, respectivement.\n",
    "\n",
    "4. **Modification de la méthode `apply_features` dans la classe `ViolaJones`**:\n",
    "   - Remplacement des tableaux NumPy par des tableaux CuPy pour accélérer les calculs de features.\n",
    "\n",
    "### Code Modifié\n",
    "\n",
    "```python\n",
    "import cupy as cp\n",
    "import math\n",
    "import pickle\n",
    "from sklearn.feature_selection import SelectPercentile, f_classif\n",
    "\n",
    "# Définitions de la classe ViolaJones et des méthodes associées (non modifiées sauf `apply_features`)\n",
    "\n",
    "def integral_image(image):\n",
    "    # Utilisation de CuPy au lieu de NumPy pour le calcul de l'image intégrale\n",
    "    # ...\n",
    "\n",
    "def scan_inclusive(array):\n",
    "    # Fonction pour réaliser un scan inclusif en utilisant CuPy\n",
    "    # ...\n",
    "\n",
    "def transpose_matrix(array):\n",
    "    # Fonction pour transposer une matrice en utilisant CuPy\n",
    "    # ...\n",
    "\n",
    "```\n",
    "\n",
    "### face_detection.py\n",
    "\n",
    "#### Fonction `integral_image`\n",
    "\n",
    "- **Ancienne Version (CPU) :** Utilisation de `numpy`.\n",
    "- **Nouvelle Version (GPU) :**\n",
    "  ```python\n",
    "  def integral_image(image):\n",
    "      \"\"\"\n",
    "      Computes the integral image representation of a picture using CuPy.\n",
    "      ...\n",
    "      \"\"\"\n",
    "      ii = cp.zeros(image.shape)\n",
    "      s = cp.zeros(image.shape)\n",
    "      for y in range(len(image)):\n",
    "          for x in range(len(image[y])):\n",
    "              s[y][x] = s[y-1][x] + image[y][x] if y-1 >= 0 else image[y][x]\n",
    "              ii[y][x] = ii[y][x-1] + s[y][x] if x-1 >= 0 else s[y][x]\n",
    "      return ii\n",
    "    ```\n",
    "    \n",
    "#### Fonction `scan_inclusive`\n",
    "\n",
    "- **Nouvelle Implémentation (GPU) :**\n",
    "  ```python\n",
    "def scan_inclusive(array):\n",
    "    return cp.cumsum(array, axis=0)\n",
    "    ```\n",
    "#### Fonction `transpose_matrix`\n",
    "\n",
    "- **Nouvelle Implémentation (GPU) :**\n",
    "  ```def transpose_matrix(array):\n",
    "    return cp.transpose(array)\n",
    "    ```\n",
    "    \n",
    "    ### Avantages de l'Utilisation de CuPy\n",
    "- **Performance Améliorée**: Les opérations sont exécutées plus rapidement sur les GPU, ce qui est bénéfique pour les calculs intensifs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "107db4f5-a265-4282-9766-740c829ab8a6",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Exercice 2\n",
    "**Améliorer la phase d'entraînement pour qu'elle traite toutes les images en une fois**\n",
    "- Aggrégez les images dans un grand tableau (comme une Sprite sheet) et traitez l'ensemble en une fois."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea443db-1b67-4dcb-bff3-6ed0454731c2",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Mise à jour du code pour l'utilisation de CuPy\n",
    "\n",
    "Les modifications suivantes ont été apportées pour permettre le traitement de toutes les images en une seule fois en utilisant CuPy :\n",
    "\n",
    "#### Fonctions `train_viola()` et `train_cascade()`\n",
    "\n",
    "- **Changement :** Utilisation d'un tableau CuPy pour stocker les images d'entraînement.\n",
    "\n",
    "  **Ancienne méthode :**\n",
    "  ```python\n",
    "  with open(\"training.pkl\", 'rb') as f:\n",
    "      training = pickle.load(f)\n",
    "    ```\n",
    "    **Nouvelle méthode :**\n",
    "    ```python\n",
    "    with open(\"training.pkl\", 'rb') as f:\n",
    "        training_data = pickle.load(f)\n",
    "    # Créer un tableau CuPy pour stocker les images d'entraînement\n",
    "    images_array = cp.array([image for image, _ in training_data])\n",
    "    ```\n",
    "    \n",
    "#### Fonction train_viola()\n",
    "- **Changement :** Modification de l'argument passé à la méthode train pour utiliser le tableau CuPy.\n",
    "**Ancienne méthode :**\n",
    "  ```python\n",
    "clf.train(training, 2429, 4548)\n",
    "    ```\n",
    "** Nouvelle méthode :**\n",
    "  ```python\n",
    "clf.train(images_array, 2429, 4548)\n",
    "    ```\n",
    "    \n",
    "#### Fonction train_cascade()\n",
    "- **Changement :** Modification de l'argument passé à la méthode train pour utiliser le tableau CuPy.\n",
    "**Ancienne méthode :**\n",
    "  ```python\n",
    "clf.train(training)\n",
    "    ```\n",
    "** Nouvelle méthode :**\n",
    "  ```python\n",
    "clf.train(images_array)\n",
    "    ```\n",
    "\n",
    "#### Fonctions integral_image(), scan_inclusive(), et transpose_matrix()\n",
    "- **Changement :** Remplacement de toutes les instances de numpy par cupy pour exploiter les capacités du GPU.\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "281ce448-2c19-4988-bac3-ea9be6c7d7e1",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Exercice 3\n",
    "\n",
    "Créez un fichier `projet.py` qui contient les méthodes suivantes :\n",
    "\n",
    "- `bench_train()`: Exécute l'entraînement en utilisant le GPU.\n",
    "- `bench_train_fast()`: Exécute l'entraînement après avoir aggrégé N images (aka Sprite sheet).\n",
    "- `bench_accuracy()`: Charge les modèles précédents et mesure la précision sur un jeu d'images test.\n",
    "- `find_face()`: Cherche une image passée en paramètre, détecte si un visage est présent sur la version en noir et blanc, marque la zone du visage (rectangle) et sauvegarde l'image résultante en couleur sur le disque.\n",
    "\n",
    "#### Fonctions Définies\n",
    "\n",
    "- `create_sprite_sheet()`: Crée une feuille de sprites à partir des images d'entraînement. Utilise `cupy` pour la gestion des tableaux.\n",
    "\n",
    "![shema de réflexion](https://i.postimg.cc/KY3DhjY8/New-Project.png)\n",
    "\n",
    "\n",
    "- `extract_images()`: Extrait les images individuelles à partir de la feuille de sprites.\n",
    "\n",
    "![shema de réflexion](https://i.postimg.cc/g2FYHB6t/4-Figure3-1-1.png)\n",
    "\n",
    "#### Entraînement (`bench_train()`)\n",
    "- Charge les données d'entraînement, crée une feuille de sprites, et extrait les images.\n",
    "- Utilise `ViolaJones` pour entraîner le modèle avec ces images.\n",
    "- Sauvegarde le modèle entraîné.\n",
    "\n",
    "#### Entraînement Rapide (`bench_train_fast()`)\n",
    "- Extrait un sous-ensemble des données d'entraînement et entraîne `ViolaJones` avec un nombre réduit de classificateurs faibles.\n",
    "- Sauvegarde le modèle entraîné.\n",
    "\n",
    "#### Évaluation (`bench_accuracy()`)\n",
    "- Charge les modèles entraînés et évalue leur précision sur un jeu de test.\n",
    "\n",
    "#### Détection de Visage (`find_face()`)\n",
    "- Charge le modèle, convertit l'image en niveaux de gris, et utilise `ViolaJones` pour détecter les visages.\n",
    "- Marque les visages détectés et sauvegarde l'image.\n",
    "\n",
    "#### Autres Fonctions\n",
    "- `integral_image()`, `scan_inclusive()`, et `transpose_matrix()` : Fonctions utilitaires pour le traitement des images.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8cc656f-3fd1-47ba-ba98-b024422d2e21",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Détection de Visage avec `find_face()`\n",
    "\n",
    "La fonction `find_face()` est conçue pour détecter des visages dans des images en utilisant le modèle de Viola-Jones. Elle prend une image en entrée, la convertit en noir et blanc, détecte le visage, marque la zone du visage avec un rectangle vert, et sauvegarde l'image résultante en couleur sur le disque. \n",
    "Voici comment elle fonctionne :\n",
    "\n",
    "## Étapes de la Fonction `find_face()`\n",
    "\n",
    "### 1. Chargement du Modèle Viola-Jones\n",
    "Le modèle Viola-Jones est chargé en mémoire pour la détection de visage.\n",
    "\n",
    "```python\n",
    "clf = ViolaJones.load(\"200\")\n",
    "```\n",
    "### 2. Lecture et Conversion de l'Image\n",
    "L'image originale est lue et convertie en niveaux de gris. Cette conversion est nécessaire car le modèle Viola-Jones fonctionne sur des images en niveaux de gris.\n",
    "\n",
    "```python\n",
    "original_image = cv2.imread(image_source)\n",
    "gray_image = cv2.cvtColor(original_image, cv2.COLOR_BGR2GRAY)\n",
    "```\n",
    "### 3. Conversion en Tableau CuPy\n",
    "L'image en niveaux de gris est convertie en tableau CuPy, qui est une bibliothèque GPU-accelérée compatible avec NumPy.\n",
    "\n",
    "```python\n",
    "image_array = cp.array(gray_image)\n",
    "```\n",
    "### 4. Détection de Visage\n",
    "La fonction classify_with_coordinates_optimized est utilisée pour détecter le visage dans l'image. Elle utilise une approche d'intégration d'image et un algorithme optimisé pour une détection rapide et précise. ( le code a été commenté au mieux)\n",
    "\n",
    "```python\n",
    "detected, coordinates = clf.classify_with_coordinates_optimized(image_array)\n",
    "```\n",
    "### 5. Marquage et Sauvegarde de l'Image\n",
    "Si un visage est détecté, la zone du visage est marquée avec un rectangle vert sur l'image originale en couleur. L'image est ensuite sauvegardée sur le disque.\n",
    "\n",
    "```python\n",
    "cv2.rectangle(original_image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "cv2.imwrite(\"src/yes.png\", original_image)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7aa565c-e042-415f-9fd7-6270085b3228",
   "metadata": {},
   "source": [
    "## Exercice 4\n",
    "\n",
    "On doit pouvoir selectionner quelle méthode exécuter avec une option \n",
    "\n",
    "- `-train` : Entraîne le classifieur Viola-Jones.\n",
    "- `-train_fast <N>` : Entraîne le classifieur Viola-Jones en utilisant une feuille de sprite.\n",
    "- `-accuracy` : Évalue la précision du classifieur Viola-Jones.\n",
    "- `-find <image_source.jpg> <image_result.jpg>` : Trouve des visages dans une image.\n",
    "\n",
    "### Structure du Code\n",
    "\n",
    "```python\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import argparse\n",
    "\n",
    "    # Initialisation du parseur d'arguments\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"-train\", action=\"store_true\", help=\"Entraîner le classifieur Viola-Jones\")\n",
    "    parser.add_argument(\"-train-fast\", action=\"store_true\", help=\"Entraîner le classifieur Viola-Jones en utilisant une feuille de sprite\")\n",
    "    parser.add_argument(\"-accuracy\", action=\"store_true\", help=\"Évaluer la précision du classifieur Viola-Jones\")\n",
    "    parser.add_argument(\"-find\", action=\"store_true\", help=\"Trouver des visages dans une image\")\n",
    "    parser.add_argument(\"image_source\", nargs=\"?\", help=\"Chemin de l'image pour trouver des visages\")\n",
    "    args = parser.parse_args()\n",
    "    ```\n",
    "\n",
    "    # Analyse des arguments passés en ligne de commande\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    # Exécution des méthodes en fonction des options sélectionnées\n",
    "    if args.train:\n",
    "        bench_train()\n",
    "    elif args.train_fast:\n",
    "        bench_train_fast()\n",
    "    elif args.accuracy:\n",
    "        bench_accuracy()\n",
    "    elif args.find:\n",
    "        find_face(args.image_source)\n",
    "    else:\n",
    "        print(\"Option non valide. Veuillez utiliser -train, -train-fast, -accuracy, ou -find.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef925294-f3ae-43ca-a3c3-91127fab168f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Testing Training ----- TROP LONG donc skipped\n",
      "\n",
      "----- Testing Fast Training -----\n",
      "Success:\n",
      " Trained 1000 classifiers out of 51705\n",
      "Trained 2000 classifiers out of 51705\n",
      "Trained 3000 classifiers out of 51705\n",
      "Trained 4000 classifiers out of 51705\n",
      "Trained 5000 classifiers out of 51705\n",
      "Trained 6000 classifiers out of 51705\n",
      "Trained 7000 classifiers out of 51705\n",
      "Trained 8000 classifiers out of 51705\n",
      "Trained 9000 classifiers out of 51705\n",
      "Trained 10000 classifiers out of 51705\n",
      "Trained 11000 classifiers out of 51705\n",
      "Trained 12000 classifiers out of 51705\n",
      "Trained 13000 classifiers out of 51705\n",
      "Trained 14000 classifiers out of 51705\n",
      "Trained 15000 classifiers out of 51705\n",
      "Trained 16000 classifiers out of 51705\n",
      "Trained 17000 classifiers out of 51705\n",
      "Trained 18000 classifiers out of 51705\n",
      "Trained 19000 classifiers out of 51705\n",
      "Trained 20000 classifiers out of 51705\n",
      "Trained 21000 classifiers out of 51705\n",
      "Trained 22000 classifiers out of 51705\n",
      "Trained 23000 classifiers out of 51705\n",
      "Trained 24000 classifiers out of 51705\n",
      "Trained 25000 classifiers out of 51705\n",
      "Trained 26000 classifiers out of 51705\n",
      "Trained 27000 classifiers out of 51705\n",
      "Trained 28000 classifiers out of 51705\n",
      "Trained 29000 classifiers out of 51705\n",
      "Trained 30000 classifiers out of 51705\n",
      "Trained 31000 classifiers out of 51705\n",
      "Trained 32000 classifiers out of 51705\n",
      "Trained 33000 classifiers out of 51705\n",
      "Trained 34000 classifiers out of 51705\n",
      "Trained 35000 classifiers out of 51705\n",
      "Trained 36000 classifiers out of 51705\n",
      "Trained 37000 classifiers out of 51705\n",
      "Trained 38000 classifiers out of 51705\n",
      "Trained 39000 classifiers out of 51705\n",
      "Trained 40000 classifiers out of 51705\n",
      "Trained 41000 classifiers out of 51705\n",
      "Trained 42000 classifiers out of 51705\n",
      "Trained 43000 classifiers out of 51705\n",
      "Trained 44000 classifiers out of 51705\n",
      "Trained 45000 classifiers out of 51705\n",
      "Trained 46000 classifiers out of 51705\n",
      "Trained 47000 classifiers out of 51705\n",
      "Trained 48000 classifiers out of 51705\n",
      "Trained 49000 classifiers out of 51705\n",
      "Trained 50000 classifiers out of 51705\n",
      "Trained 51000 classifiers out of 51705\n",
      "Trained 1000 classifiers out of 51705\n",
      "Trained 2000 classifiers out of 51705\n",
      "Trained 3000 classifiers out of 51705\n",
      "Trained 4000 classifiers out of 51705\n",
      "Trained 5000 classifiers out of 51705\n",
      "Trained 6000 classifiers out of 51705\n",
      "Trained 7000 classifiers out of 51705\n",
      "Trained 8000 classifiers out of 51705\n",
      "Trained 9000 classifiers out of 51705\n",
      "Trained 10000 classifiers out of 51705\n",
      "Trained 11000 classifiers out of 51705\n",
      "Trained 12000 classifiers out of 51705\n",
      "Trained 13000 classifiers out of 51705\n",
      "Trained 14000 classifiers out of 51705\n",
      "Trained 15000 classifiers out of 51705\n",
      "Trained 16000 classifiers out of 51705\n",
      "Trained 17000 classifiers out of 51705\n",
      "Trained 18000 classifiers out of 51705\n",
      "Trained 19000 classifiers out of 51705\n",
      "Trained 20000 classifiers out of 51705\n",
      "Trained 21000 classifiers out of 51705\n",
      "Trained 22000 classifiers out of 51705\n",
      "Trained 23000 classifiers out of 51705\n",
      "Trained 24000 classifiers out of 51705\n",
      "Trained 25000 classifiers out of 51705\n",
      "Trained 26000 classifiers out of 51705\n",
      "Trained 27000 classifiers out of 51705\n",
      "Trained 28000 classifiers out of 51705\n",
      "Trained 29000 classifiers out of 51705\n",
      "Trained 30000 classifiers out of 51705\n",
      "Trained 31000 classifiers out of 51705\n",
      "Trained 32000 classifiers out of 51705\n",
      "Trained 33000 classifiers out of 51705\n",
      "Trained 34000 classifiers out of 51705\n",
      "Trained 35000 classifiers out of 51705\n",
      "Trained 36000 classifiers out of 51705\n",
      "Trained 37000 classifiers out of 51705\n",
      "Trained 38000 classifiers out of 51705\n",
      "Trained 39000 classifiers out of 51705\n",
      "Trained 40000 classifiers out of 51705\n",
      "Trained 41000 classifiers out of 51705\n",
      "Trained 42000 classifiers out of 51705\n",
      "Trained 43000 classifiers out of 51705\n",
      "Trained 44000 classifiers out of 51705\n",
      "Trained 45000 classifiers out of 51705\n",
      "Trained 46000 classifiers out of 51705\n",
      "Trained 47000 classifiers out of 51705\n",
      "Trained 48000 classifiers out of 51705\n",
      "Trained 49000 classifiers out of 51705\n",
      "Trained 50000 classifiers out of 51705\n",
      "Trained 51000 classifiers out of 51705\n",
      "Trained 1000 classifiers out of 51705\n",
      "Trained 2000 classifiers out of 51705\n",
      "Trained 3000 classifiers out of 51705\n",
      "Trained 4000 classifiers out of 51705\n",
      "Trained 5000 classifiers out of 51705\n",
      "Trained 6000 classifiers out of 51705\n",
      "Trained 7000 classifiers out of 51705\n",
      "Trained 8000 classifiers out of 51705\n",
      "Trained 9000 classifiers out of 51705\n",
      "Trained 10000 classifiers out of 51705\n",
      "Trained 11000 classifiers out of 51705\n",
      "Trained 12000 classifiers out of 51705\n",
      "Trained 13000 classifiers out of 51705\n",
      "Trained 14000 classifiers out of 51705\n",
      "Trained 15000 classifiers out of 51705\n",
      "Trained 16000 classifiers out of 51705\n",
      "Trained 17000 classifiers out of 51705\n",
      "Trained 18000 classifiers out of 51705\n",
      "Trained 19000 classifiers out of 51705\n",
      "Trained 20000 classifiers out of 51705\n",
      "Trained 21000 classifiers out of 51705\n",
      "Trained 22000 classifiers out of 51705\n",
      "Trained 23000 classifiers out of 51705\n",
      "Trained 24000 classifiers out of 51705\n",
      "Trained 25000 classifiers out of 51705\n",
      "Trained 26000 classifiers out of 51705\n",
      "Trained 27000 classifiers out of 51705\n",
      "Trained 28000 classifiers out of 51705\n",
      "Trained 29000 classifiers out of 51705\n",
      "Trained 30000 classifiers out of 51705\n",
      "Trained 31000 classifiers out of 51705\n",
      "Trained 32000 classifiers out of 51705\n",
      "Trained 33000 classifiers out of 51705\n",
      "Trained 34000 classifiers out of 51705\n",
      "Trained 35000 classifiers out of 51705\n",
      "Trained 36000 classifiers out of 51705\n",
      "Trained 37000 classifiers out of 51705\n",
      "Trained 38000 classifiers out of 51705\n",
      "Trained 39000 classifiers out of 51705\n",
      "Trained 40000 classifiers out of 51705\n",
      "Trained 41000 classifiers out of 51705\n",
      "Trained 42000 classifiers out of 51705\n",
      "Trained 43000 classifiers out of 51705\n",
      "Trained 44000 classifiers out of 51705\n",
      "Trained 45000 classifiers out of 51705\n",
      "Trained 46000 classifiers out of 51705\n",
      "Trained 47000 classifiers out of 51705\n",
      "Trained 48000 classifiers out of 51705\n",
      "Trained 49000 classifiers out of 51705\n",
      "Trained 50000 classifiers out of 51705\n",
      "Trained 51000 classifiers out of 51705\n",
      "\n",
      "\n",
      "----- Testing Accuracy -----\n",
      "Success:\n",
      " cub/detail/detect_cuda_runtime.cuh(39): warning: cuda_runtime_api.h: [jitify] File not found\n",
      "../util_type.cuh(42): warning: cuda.h: [jitify] File not found\n",
      "cupy_jitify_exercise(10): warning: cooperative_groups.h: [jitify] File not found\n",
      "cupy_jitify_exercise(11): warning: cooperative_groups/memcpy_async.h: [jitify] File not found\n",
      "Évaluation du modèle standard:\n",
      "Accuracy: 97.86%\n",
      "Précision: 0.04\n",
      "Rappel: 0.00\n",
      "Score F1: 0.01\n",
      "Temps moyen de classification: 0.0516 secondes\n",
      "Taux de faux positifs: 0.00\n",
      "Taux de faux négatifs: 1.00\n",
      "\n",
      "Évaluation du modèle rapide:\n",
      "Accuracy: 47.07%\n",
      "Précision: 0.02\n",
      "Rappel: 0.62\n",
      "Score F1: 0.04\n",
      "Temps moyen de classification: 0.0010 secondes\n",
      "Taux de faux positifs: 0.53\n",
      "Taux de faux négatifs: 0.38\n",
      "\n",
      "\n",
      "----- Testing Face Detection -----\n",
      "Success:\n",
      " Chargement du modèle...\n",
      "Lecture et conversion de l'image...\n",
      "Conversion de l'image en tableau CuPy...\n",
      "Classification de l'image...\n",
      "DETECTED\n",
      "Figure(640x480)\n",
      "\n",
      "\n",
      "----- Testing Face Detection on a Photo That is Not a Face-----\n",
      "Success:\n",
      " Chargement du modèle...\n",
      "Lecture et conversion de l'image...\n",
      "Conversion de l'image en tableau CuPy...\n",
      "Classification de l'image...\n",
      "Aucun visage détecté\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import pickle\n",
    "\n",
    "def run_command(command):\n",
    "    \"\"\" Exécute une commande dans le terminal et affiche sa sortie. \"\"\"\n",
    "    process = subprocess.Popen(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE, shell=True)\n",
    "    output, error = process.communicate()\n",
    "    if process.returncode == 0:\n",
    "        print(\"Success:\\n\", output.decode())\n",
    "    else:\n",
    "        print(\"Error:\\n\", error.decode())\n",
    "\n",
    "def main():\n",
    "    script_path = 'projet.py'\n",
    "\n",
    "    print(\"----- Testing Training ----- TROP LONG donc skipped\")\n",
    "    # run_command(f'python {script_path} -train') fonctionnel, retirez le # pour le tester \n",
    "    #(je l'ai mis en commentaire parce que ça mettait beaucoup de temps + ça prend beaucoup de place sur le compte rendu)\n",
    "    \n",
    "    print(\"\\n----- Testing Fast Training -----\")\n",
    "    run_command(f'python {script_path} -train-fast 10')\n",
    "\n",
    "    print(\"\\n----- Testing Accuracy -----\")\n",
    "    run_command(f'python {script_path} -accuracy')\n",
    "\n",
    "    print(\"\\n----- Testing Face Detection -----\")\n",
    "    run_command(f'python {script_path} -find src/visage.jpg')\n",
    "    \n",
    "    print(\"\\n----- Testing Face Detection on a Photo That is Not a Face-----\")\n",
    "    run_command(f'python {script_path} -find src/lotus.jpg')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7506fab8-dc18-4268-8205-b03b1b989ead",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Visage détecté : rectangle vert sur le visage :\n",
    "![détection visage](src/yes.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "141ff2e6-8443-4c9c-b0a2-6bafba780dae",
   "metadata": {
    "tags": []
   },
   "source": [
    "## AUCUN Visage détecté : \n",
    "![détection visage](src/lotus.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "466ec574-c286-4e6f-9140-e97a0cbf6a7e",
   "metadata": {},
   "source": [
    "## Prérequis & installations : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ba908b-2689-434d-a98b-e3a40bb62c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -U setuptools pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73ec7d4-6768-4637-8c50-492350dab86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install cupy-cuda12x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc35e72-2390-476a-9b1a-5118296e937c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install opencv-python"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
